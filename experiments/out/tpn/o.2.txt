================================================================================
SLTP v.0.2.0
================================================================================
================================================================================
(pid: 23436) STARTING STEP #1: Expand the state space of the training instances
================================================================================
0it [00:00, ?it/s]9it [00:00, 494.64it/s]
0it [00:00, ?it/s]State space of instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x12_0.json" stored in "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/samples_layout_2x12_0.txt"
[# nodes: 11, # goals: 2, # edges: 216, total time: 0.01814 seconds]
3it [00:00, 441.27it/s]
0it [00:00, ?it/s]State space of instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x13_0.json" stored in "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/samples_layout_2x13_0.txt"
[# nodes: 5, # goals: 2, # edges: 78, total time: 0.00676 seconds]
15it [00:00, 360.04it/s]
State space of instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x16_0.json" stored in "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/samples_layout_2x16_0.txt"
[# nodes: 17, # goals: 2, # edges: 480, total time: 0.04162 seconds]
================================================================================
END OF STEP #1: Expand the state space of the training instances. 0.09 CPU sec - 65.82 MB
================================================================================
================================================================================
(pid: 23441) STARTING STEP #2: Generation of the training sample
================================================================================
2021-02-16 13:35:47 INFO     Loading state space samples...
2021-02-16 13:35:47 INFO     samples_layout_2x12_0: #lines-raw-file=227, #states-by-id=11, #transition-entries=9, #transitions=34
2021-02-16 13:35:47 INFO     samples_layout_2x13_0: #lines-raw-file=83, #states-by-id=5, #transition-entries=3, #transitions=7
2021-02-16 13:35:47 INFO     samples_layout_2x16_0: #lines-raw-file=497, #states-by-id=17, #transition-entries=15, #transitions=79
2021-02-16 13:35:47 INFO     Entire sample: roots: 3, states: 33, transitions: 120 (31 optimal), goals: 3, alive: 27
2021-02-16 13:35:47 INFO     Resampled states logged at "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/sample.txt"
2021-02-16 13:35:47 INFO     Printing SAT transition matrix with 33 states, 33 expanded states and 120 transitions to '/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/transitions-info.io'
================================================================================
END OF STEP #2: Generation of the training sample. 0.02 CPU sec - 65.82 MB
================================================================================
================================================================================
(pid: 23455) STARTING STEP #3: Generate the pool of candidate features
================================================================================
2021-02-16 13:35:47 INFO     Starting generation of feature pool. State sample used to detect redundancies: roots: 3, states: 33, transitions: 120 (31 optimal), goals: 3, alive: 27
2021-02-16 13:35:47 INFO     Printing sample information to '/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/sample.io'
2021-02-16 13:35:47 INFO     Invoking C++ feature generation module
2021-02-16 13:35:47 INFO     Executing "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/venv/src/d2l/src/generators/featuregen --complexity-bound 5 --timeout -1 --dist-complexity-bound 5 --cond-complexity-bound 0 --workspace /home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2" on directory "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/experiments"
reading '/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/transitions-info.io
BASIS: #concepts=6, #roles=10
ROLES: #roles=40
Start of iteration 0: #total-concepts=0, #concepts-in-last-layer=0
Result of iteration 0: #concepts-in-layer=5, #pruned-concepts=1
Start of iteration 1: #total-concepts=5, #concepts-in-last-layer=5
Result of iteration 1: #concepts-in-layer=155, #pruned-concepts=260
Start of iteration 2: #total-concepts=160, #concepts-in-last-layer=155
Result of iteration 2: #concepts-in-layer=1082, #pruned-concepts=2732
Start of iteration 3: #total-concepts=1242, #concepts-in-last-layer=1082
Result of iteration 3: #concepts-in-layer=13, #pruned-concepts=1355
Start of iteration 4: #total-concepts=1255, #concepts-in-last-layer=13
Result of iteration 4: #concepts-in-layer=0, #pruned-concepts=0
dl::Factory: #concepts-final=1255
A total of 0 features were marked as goal-identifying
Generating cardinality features...
Generating distance features...
FEATURES: #features=204, #nullary=1, #boolean=0, #numerical=203, #distance=0, #conditional=0, #comparison=0
Serializing all concepts and features to:
	/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/serialized-concepts.io
	/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/serialized-features.io
2021-02-16 13:35:48 INFO     Transforming generator output to numpy format...
2021-02-16 13:35:48 INFO     Reading feature information from /home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/feature-info.io
2021-02-16 13:35:48 INFO     Read 204 features: 203 numeric + 1 binary
2021-02-16 13:35:48 INFO     Reading denotation matrix from /home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/feature-matrix.io
2021-02-16 13:35:48 INFO     Read denotation matrix with dimensions (33, 204)
2021-02-16 13:35:48 INFO     Printing matrix of 204 features x 33 states to '/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/feature-matrix.dat'
================================================================================
END OF STEP #3: Generate the pool of candidate features. 0.78 CPU sec - 73.14 MB
================================================================================
================================================================================
(pid: 23460) STARTING STEP #4: C++ CNF generation module
================================================================================
2021-02-16 13:35:48 INFO     Running standard non-incremental approach
2021-02-16 13:35:48 INFO     Invoking C++ CNF generation module
2021-02-16 13:35:48 INFO     Executing "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/venv/src/d2l/src/generators/cnfgen --workspace /home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2 --encoding d2l --use-equivalence-classes --v_slack 2 --cross_instance_constraints" on directory "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/experiments"
reading '/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/transitions-info.io
reading '/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/feature-matrix.dat
Training sample: TransitionSample[instances: 3, states: 33, transitions: 120 (120 alive: 34/7/79), deadends: 3, goals: 3, features: 204, est. size: 0.01 MB.]
Number of transitions/equivalence classes: 120/38
Number of necessarily bad transitions/classes: 27/9
Using an upper bound for V_pi(s) values of 6
A total of 395 variables were created
	Select(f): 204
	Good(s, s'): 29
	V(s, d): 162
Generating CNF encoding for 27 alive states, 120 alive-to-solvable and alive-to-dead transitions and 38 transition equivalence classes
Posting distinguishability constraints for 735 pairs of transitions
Posting (weighted) soft constraints for 204 features
A total of 1938 clauses were created
	(Weighted) Select(f): 204
	Policy completeness [1]: 27
	V descending along good transitions [2]: 540
	V is total function within bounds [3,4]: 432
	Transition-separation clauses [5,6]: 735
	Goal clauses [7]: 0
Total-time: 0.05
CNF Theory: 395 vars + 1938 clauses
2021-02-16 13:35:48 INFO     Executing (timeout: None s.) "['open-wbo_static', '/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2/theory.wsat']" on directory "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/workspace/tpn_2"
2021-02-16 13:35:48 INFO     Optimal MAXSAT solution with cost 4 found
Features (#: 2; total k: 4; max k = 3):
  Atom[player0] [k=1]
  Num[Forall(same_col,cell-hv-empty)] [k=3]
Invariants: Atom[player0]>0
Policy:
  1. Atom[player0]>0 AND Num[Forall(same_col,cell-hv-empty)]=0 -> {Atom[player0] NILs, Num[Forall(same_col,cell-hv-empty)] INCs}
  2. Atom[player0]>0 AND Num[Forall(same_col,cell-hv-empty)]>0 -> {Atom[player0] NILs, Num[Forall(same_col,cell-hv-empty)] INCs}
================================================================================
END OF STEP #4: C++ CNF generation module. 0.09 CPU sec - 73.14 MB
================================================================================
================================================================================
(pid: 23466) STARTING STEP #5: Testing of the D2L policy
================================================================================
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x10_0.json"
2021-02-16 13:35:48 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:48 INFO     The solution was: [(8, 0), (4, 0), (9, 1)]
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x11_0.json"
2021-02-16 13:35:48 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:48 INFO     The solution was: [(9, 1), (4, 0), (10, 1)]
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x12_0.json"
2021-02-16 13:35:48 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:48 INFO     The solution was: [(10, 0), (4, 0), (11, 1)]
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x13_0.json"
2021-02-16 13:35:48 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:48 INFO     The solution was: [(4, 0), (4, 0), (12, 1)]
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x14_0.json"
2021-02-16 13:35:48 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:48 INFO     The solution was: [(12, 1), (4, 0), (13, 1)]
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x16_0.json"
2021-02-16 13:35:48 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:48 INFO     The solution was: [(14, 1), (4, 0), (15, 1)]
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x16_1.json"
2021-02-16 13:35:48 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:48 INFO     The solution was: [(14, 1), (4, 0), (15, 1)]
2021-02-16 13:35:48 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x17_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(15, 1), (4, 0), (16, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x18_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(16, 1), (4, 0), (17, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x19_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(17, 0), (4, 0), (18, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x2_1.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(0, 1), (0, 1), (1, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x3_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 4 nodes
2021-02-16 13:35:49 INFO     The solution was: [(0, 1), (0, 1), (0, 1), (2, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x3_1.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(0, 1), (0, 1), (2, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x3_2.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 4 nodes
2021-02-16 13:35:49 INFO     The solution was: [(0, 0), (0, 1), (0, 1), (2, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x4_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(2, 1), (0, 1), (3, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x5_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(0, 1), (0, 1), (4, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x5_1.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(3, 1), (0, 1), (4, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x5_2.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(3, 1), (0, 1), (4, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x6_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(4, 0), (0, 1), (5, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x7_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(5, 1), (0, 1), (6, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x7_1.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 4 nodes
2021-02-16 13:35:49 INFO     The solution was: [(4, 0), (0, 1), (0, 1), (6, 1)]
2021-02-16 13:35:49 INFO     Testing policy on instance "/home/orbital/ws/research/learning-generalized-policies/gpl-fond/learning-generalized-policies/benchmarks/two_pile_nim/layout_2x2_0.json"
2021-02-16 13:35:49 INFO     Goal found after expanding 3 nodes
2021-02-16 13:35:49 INFO     The solution was: [(4, 0), (0, 1), (5, 1)]
2021-02-16 13:35:49 INFO     Learnt policy solves the 100.0% of test instances: 22/22
2021-02-16 13:35:49 INFO     Solved instances: ['layout_2x10_0', 'layout_2x11_0', 'layout_2x12_0', 'layout_2x13_0', 'layout_2x14_0', 'layout_2x16_0', 'layout_2x16_1', 'layout_2x17_0', 'layout_2x18_0', 'layout_2x19_0', 'layout_2x2_1', 'layout_2x3_0', 'layout_2x3_1', 'layout_2x3_2', 'layout_2x4_0', 'layout_2x5_0', 'layout_2x5_1', 'layout_2x5_2', 'layout_2x6_0', 'layout_2x7_0', 'layout_2x7_1', 'layout_2x2_0']
2021-02-16 13:35:49 INFO     Unsolved instances: []
================================================================================
END OF STEP #5: Testing of the D2L policy. 0.80 CPU sec - 73.14 MB
================================================================================
